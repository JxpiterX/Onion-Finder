package scanner

import (
	"bytes"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"sync"
	"sync/atomic"
	"time"
	"unicode/utf16"

	"onion-finder/internal/model"
)

const (
	ChunkSize    = 1024 * 1024
	NumWorkers   = 8
	ChunkOverlap = 128
)

var onionRegex = regexp.MustCompile(`(?i)[a-z2-7]{56,}\.onion`)

type FileJob struct {
	Path string
	Info os.FileInfo
}

func ScanForOnions(root string) ([]model.Onion, error) {
	results := []model.Onion{}
	resultsMux := sync.Mutex{}
	seen := make(map[string]bool)

	jobs := make(chan FileJob, 100)
	wg := sync.WaitGroup{}

	var filesProcessed uint64
	start := time.Now()

	// ðŸ”¹ Progress ticker
	done := make(chan struct{})
	go func() {
		ticker := time.NewTicker(5 * time.Second)
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				fmt.Printf(
					"[*] Scanning... files processed: %d | onions found: %d | elapsed: %s\n",
					atomic.LoadUint64(&filesProcessed),
					len(results),
					time.Since(start).Truncate(time.Second),
				)
			case <-done:
				return
			}
		}
	}()

	// ðŸ”¹ Workers
	for i := 0; i < NumWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for job := range jobs {
				onions := scanFile(job.Path)
				atomic.AddUint64(&filesProcessed, 1)

				resultsMux.Lock()
				for _, onion := range onions {
					key := onion.Value + "|" + onion.Path
					if !seen[key] {
						seen[key] = true
						results = append(results, onion)
					}
				}
				resultsMux.Unlock()
			}
		}()
	}

	err := filepath.WalkDir(root, func(path string, d os.DirEntry, err error) error {
		if err != nil {
			return nil
		}

		filename := filepath.Base(path)
		matches := onionRegex.FindAllString(filename, -1)
		if len(matches) > 0 {
			resultsMux.Lock()
			for _, match := range matches {
				key := strings.ToLower(match) + "|" + path
				if !seen[key] {
					seen[key] = true
					results = append(results, model.Onion{
						Value: strings.ToLower(match),
						Path:  path,
					})
				}
			}
			resultsMux.Unlock()
		}

		if d.IsDir() {
			return nil
		}

		info, err := d.Info()
		if err != nil || info.Size() > 500*1024*1024 {
			return nil
		}

		jobs <- FileJob{Path: path, Info: info}
		return nil
	})

	close(jobs)
	wg.Wait()
	close(done)

	fmt.Printf(
		"[+] Scan finished: %d files processed | %d onions found | total time: %s\n",
		filesProcessed,
		len(results),
		time.Since(start).Truncate(time.Second),
	)

	return results, err
}

func scanFile(path string) []model.Onion {
	results := []model.Onion{}
	seen := make(map[string]bool)

	file, err := os.Open(path)
	if err != nil {
		return results
	}
	defer file.Close()

	firstChunk := make([]byte, 4096)
	n, _ := file.Read(firstChunk)
	if n == 0 {
		return results
	}
	file.Seek(0, 0)

	isUTF16LE := detectUTF16LE(firstChunk[:n])

	if isUTF16LE {
		data, err := os.ReadFile(path)
		if err != nil {
			return results
		}
		content := decodeUTF16LE(data)
		matches := onionRegex.FindAllString(content, -1)
		for _, match := range matches {
			key := strings.ToLower(match)
			if !seen[key] {
				seen[key] = true
				results = append(results, model.Onion{
					Value: key,
					Path:  path,
				})
			}
		}
	} else {
		results = scanFileChunked(file, path)
	}

	return results
}

func scanFileChunked(file *os.File, path string) []model.Onion {
	results := []model.Onion{}
	seen := make(map[string]bool)

	buffer := make([]byte, ChunkSize+ChunkOverlap)
	overlap := make([]byte, 0)

	for {
		n, err := file.Read(buffer[len(overlap):])
		if n == 0 {
			break
		}

		copy(buffer, overlap)
		totalLen := len(overlap) + n

		matches := scanChunk(buffer[:totalLen])
		for _, match := range matches {
			key := strings.ToLower(match)
			if !seen[key] {
				seen[key] = true
				results = append(results, model.Onion{
					Value: key,
					Path:  path,
				})
			}
		}

		if err != nil {
			break
		}

		if totalLen > ChunkOverlap {
			overlap = make([]byte, ChunkOverlap)
			copy(overlap, buffer[totalLen-ChunkOverlap:totalLen])
		}
	}

	return results
}

func scanChunk(data []byte) []string {
	results := []string{}

	matches := onionRegex.FindAll(data, -1)
	for _, match := range matches {
		results = append(results, string(match))
	}

	cleaned := extractOnionChars(data)
	matches2 := onionRegex.FindAllString(cleaned, -1)
	results = append(results, matches2...)

	return results
}

func extractOnionChars(data []byte) string {
	var buf bytes.Buffer
	buf.Grow(len(data) / 2)

	for _, b := range data {
		if b == 0x00 {
			continue
		}
		if isValidOnionChar(b) {
			if b >= 'A' && b <= 'Z' {
				b = b + 32
			}
			buf.WriteByte(b)
		} else {
			if buf.Len() > 0 && buf.Bytes()[buf.Len()-1] != ' ' {
				buf.WriteByte(' ')
			}
		}
	}

	return buf.String()
}

func isValidOnionChar(b byte) bool {
	return (b >= 'a' && b <= 'z') ||
		(b >= 'A' && b <= 'Z') ||
		(b >= '2' && b <= '7') ||
		b == '.'
}

func detectUTF16LE(data []byte) bool {
	if len(data) < 2 {
		return false
	}
	if data[0] == 0xFF && data[1] == 0xFE {
		return true
	}
	nullCount := 0
	sampleSize := min(len(data), 200)
	for i := 1; i < sampleSize; i += 2 {
		if data[i] == 0x00 {
			nullCount++
		}
	}
	return nullCount > sampleSize/4
}

func decodeUTF16LE(data []byte) string {
	if len(data) < 2 {
		return ""
	}

	start := 0
	if data[0] == 0xFF && data[1] == 0xFE {
		start = 2
	}

	if (len(data)-start)%2 != 0 {
		data = data[:len(data)-1]
	}

	u16 := make([]uint16, (len(data)-start)/2)
	for i := 0; i < len(u16); i++ {
		u16[i] = uint16(data[start+i*2]) | uint16(data[start+i*2+1])<<8
	}

	return string(utf16.Decode(u16))
}
